{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b348f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814ac7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nlp_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f3f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(text):\n",
    "    text = re.sub(r'<.*?>', '', text)           \n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)       \n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(lambda cw : remove_tags(cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aaf4f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     i seriously hate one subject to death but now ...    fear\n",
       "1                    im so full of life i feel appalled   anger\n",
       "2     i sit here to write i start to dig out my feel...    fear\n",
       "3     ive been really angry with r and i feel like a...     joy\n",
       "4     i feel suspicious if there is no one outside l...    fear\n",
       "...                                                 ...     ...\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68421abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4076f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7456513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Comment'] = df['Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa58baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously hate one subject death feel reluctan...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im full life feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sit write start dig feelings think afraid acce...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive really angry r feel like idiot trusting fi...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel suspicious one outside like rapture happe...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>begun feel distressed</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>left feeling annoyed angry thinking center stu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>ever get married everything ready offer got to...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>feel reluctant applying want able find company...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>wanted apologize feel like heartless bitch</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     seriously hate one subject death feel reluctan...    fear\n",
       "1                            im full life feel appalled   anger\n",
       "2     sit write start dig feelings think afraid acce...    fear\n",
       "3     ive really angry r feel like idiot trusting fi...     joy\n",
       "4     feel suspicious one outside like rapture happe...    fear\n",
       "...                                                 ...     ...\n",
       "5932                              begun feel distressed    fear\n",
       "5933  left feeling annoyed angry thinking center stu...   anger\n",
       "5934  ever get married everything ready offer got to...     joy\n",
       "5935  feel reluctant applying want able find company...    fear\n",
       "5936         wanted apologize feel like heartless bitch   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8039839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously hate one subject death feel reluctan...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im full life feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sit write start dig feeling think afraid accep...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive really angry r feel like idiot trusting fi...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel suspicious one outside like rapture happe...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>begun feel distressed</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>left feeling annoyed angry thinking center stu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>ever get married everything ready offer got to...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>feel reluctant applying want able find company...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>wanted apologize feel like heartless bitch</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     seriously hate one subject death feel reluctan...    fear\n",
       "1                           im full life feel appalled    anger\n",
       "2     sit write start dig feeling think afraid accep...    fear\n",
       "3     ive really angry r feel like idiot trusting fi...     joy\n",
       "4     feel suspicious one outside like rapture happe...    fear\n",
       "...                                                 ...     ...\n",
       "5932                             begun feel distressed     fear\n",
       "5933  left feeling annoyed angry thinking center stu...   anger\n",
       "5934  ever get married everything ready offer got to...     joy\n",
       "5935  feel reluctant applying want able find company...    fear\n",
       "5936        wanted apologize feel like heartless bitch    anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "df['Comment'] = df.Comment.apply(lemmatize_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbcdbbf",
   "metadata": {},
   "source": [
    "# **STEPS COMPLETED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2d5f8",
   "metadata": {},
   "source": [
    "**TEXT LOADING :** Loaded the data set and printed the head section of the file \n",
    "\n",
    "**STOP WORD REMOVAL :** Removed the stopwords (words with no meaning + more frequency) from the comments\n",
    "\n",
    "**TOKENZIATION :** Did tokenizaiton where we splited the set into tokens with help of whitespace tokenzier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "555793d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "x = tfidf.fit_transform(df['Comment'])  \n",
    "y = df['Emotion']        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4d8e1",
   "metadata": {},
   "source": [
    "**TF - IDF :** Here we convert the text into vector with weights , where we compute weight for each words and then assign them to each of them . Help to assign more weights to those words which are more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee1114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Comments = df['Comment'].values\n",
    "emotion = df['Emotion'].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_emotion = encoder.fit_transform(emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c1efa",
   "metadata": {},
   "source": [
    "**Label Encoder :** Here we encode the labels into 0 and 1 since the systm is not able to decode text values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fecf85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55ebc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentances , test_sentances , train_labels , test_labels = train_test_split(Comments , encoded_emotion , stratify= encoded_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596aa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "517f1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentances)\n",
    "word_index = tokenizer.word_index\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentances)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentances)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9872c392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │       \u001b[38;5;34m300,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m3,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m75\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,651</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m387,651\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,651</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m387,651\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the number of unique emotions\n",
    "num_classes = len(encoder.classes_)\n",
    "\n",
    "# Model initialization updated for Multi-Class\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    # Change 1 to num_classes and sigmoid to softmax\n",
    "    keras.layers.Dense(num_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "# Change loss to sparse_categorical_crossentropy\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_length))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f9130da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.5190 - loss: 0.9609 - val_accuracy: 0.8296 - val_loss: 0.4654\n",
      "Epoch 2/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9438 - loss: 0.1726 - val_accuracy: 0.9081 - val_loss: 0.2858\n",
      "Epoch 3/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.9830 - loss: 0.0518 - val_accuracy: 0.9058 - val_loss: 0.2979\n",
      "Epoch 4/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9905 - loss: 0.0281 - val_accuracy: 0.9013 - val_loss: 0.3012\n",
      "Epoch 5/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.9955 - loss: 0.0158 - val_accuracy: 0.9103 - val_loss: 0.3227\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded, train_labels,\n",
    "                    epochs=num_epochs, verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6c758cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b312c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
      "Accuracy of prediction on test set:  0.9313131313131313\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for all classes\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "# Use argmax to get the index of the highest probability\n",
    "pred_labels = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(\"Accuracy of prediction on test set: \", accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00969e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Emotion'])\n",
    "\n",
    "predicted_emotions = le.inverse_transform(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdde068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Comment: I am absolutely delighted with how my project turned out!\n",
      "Predicted Emotion: joy\n",
      "----------------------------------------\n",
      "Comment: I am so frustrated because the app keeps crashing!\n",
      "Predicted Emotion: anger\n",
      "----------------------------------------\n",
      "Comment: I was suddenly terrified when I heard a loud noise in the dark.\n",
      "Predicted Emotion: fear\n",
      "----------------------------------------\n",
      "Comment: I was terrified of the ride, but then I felt a huge rush of joy.\n",
      "Predicted Emotion: fear\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reviews to predict\n",
    "# New test comments\n",
    "Comment = [\n",
    "    \"I am absolutely delighted with how my project turned out!\",\n",
    "    \"I am so frustrated because the app keeps crashing!\",\n",
    "    \"I was suddenly terrified when I heard a loud noise in the dark.\",\n",
    "    \"I was terrified of the ride, but then I felt a huge rush of joy.\"\n",
    "]\n",
    "sequences = tokenizer.texts_to_sequences(Comment)\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# Get probabilities\n",
    "prediction = model.predict(padded)\n",
    "\n",
    "# Get the best class index for each sentence\n",
    "pred_indices = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Convert indices back to original text labels\n",
    "predicted_names = encoder.inverse_transform(pred_indices)\n",
    "\n",
    "for i in range(len(Comment)):\n",
    "    print(f\"Comment: {Comment[i]}\")\n",
    "    print(f\"Predicted Emotion: {predicted_names[i]}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
